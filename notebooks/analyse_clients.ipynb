{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "da3498b3",
   "metadata": {},
   "source": [
    "# Analyse de la qualit√© des donn√©es du fichier Clients_Master\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9779ff83",
   "metadata": {},
   "source": [
    "## R√©sum√© des anomalies observ√©es\n",
    "- 500 clients au lieu de 300 000 clients actifs mentionn√©s dans l'√©nonc√©\n",
    "- 18 doublons (3%)\n",
    "- 2 doublons \"partiels\": les champs sont identiques √† l'exception de ville (renseign√© /null)\n",
    "<br> probl√®me d'unicit√© pour l'ID --> deux sources ont pris le m√™me id mais on fait deux enregistrements au lieu d'une mise √† jour de la ville du client\n",
    "- 17% de villes non renseign√©es\n",
    "<br> --> saisie manuelle facultative\n",
    "- 61% des lignes comportent des villes qui n'existe pas ou son mal orthographi√©es (Pariss)\n",
    "<br> --> saisie manuelle (faute de frappe, mauvais champs s√©lectionn√©)\n",
    "- 177 emails invalides\n",
    "  - Emails = 'invalid_email' : 10 (1.9%)\n",
    "  - Emails invalides (pr√©sence d'accents) : 167 (32.1%) dont 14 avec des espaces"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4415e91",
   "metadata": {},
   "source": [
    "- Les champs nom et pr√©nom ne pr√©sentent pas d'anomalie (compl√©tude OK)\n",
    "- Il n'y a pas d'incoh√©rence entre les dates d'inscription et de derni√®re activit√©"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e800493",
   "metadata": {},
   "source": [
    "### Points positifs\n",
    "- ‚úÖ **RGPD: conservation des donn√©es** pas de client dans la BDD avec activit√© > 3 ans (+5 ans archives)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6566f5a",
   "metadata": {},
   "source": [
    "## Proposition d'une correction\n",
    "- supprimer les doublons (pas de perte de donn√©es)\n",
    "<br>--> 18 lignes supprim√©es\n",
    "<br> --> 2 lignes avec ID en doublon supprim√©es\n",
    "- correction automatique avec Fuzzy matching = 1 353 lignes corrig√©es\n",
    "- suppression des noms de villes invalides non corrigeables\n",
    "<br> --> donn√©e inexploitable = 103 villes null\n",
    "- correction des accents sur les emails"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5aa13eee",
   "metadata": {},
   "source": [
    "## Ce que l'on ne peut pas corriger\n",
    "- villes non renseign√©es (non bloquant pour l'analyse)\n",
    "- email non renseign√© (invalid) car boutiques physiques donc email facultatif\n",
    "<br> --> pas d'email en doublon en dehors de ceux invalid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c3a4b8d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import requests\n",
    "import re\n",
    "import unicodedata\n",
    "from fuzzywuzzy import process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f08a9b01",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clients = pd.read_csv('../data/raw/Clients_Master.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "396b5719",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUDIT DATAFRAME CLIENTS\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>client_id</th>\n",
       "      <th>nom</th>\n",
       "      <th>prenom</th>\n",
       "      <th>email</th>\n",
       "      <th>ville</th>\n",
       "      <th>date_inscription</th>\n",
       "      <th>derniere_activite</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Rey</td>\n",
       "      <td>Alexandrie</td>\n",
       "      <td>alexandrie.rey@live.com</td>\n",
       "      <td>Lejeune</td>\n",
       "      <td>2023-10-15</td>\n",
       "      <td>2025-01-21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Lagarde</td>\n",
       "      <td>Eug√®ne</td>\n",
       "      <td>eug√®ne.lagarde@yahoo.fr</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2024-07-31</td>\n",
       "      <td>2025-08-25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Gaudin</td>\n",
       "      <td>Aim√©e</td>\n",
       "      <td>aim√©e.gaudin@sfr.fr</td>\n",
       "      <td>Lopezdan</td>\n",
       "      <td>2024-01-03</td>\n",
       "      <td>2025-10-19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Faivre</td>\n",
       "      <td>No√´l</td>\n",
       "      <td>no√´l.faivre@voila.fr</td>\n",
       "      <td>Saint Eug√®ne</td>\n",
       "      <td>2023-08-01</td>\n",
       "      <td>2025-07-11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Faure</td>\n",
       "      <td>V√©ronique</td>\n",
       "      <td>v√©ronique.faure@club-internet.fr</td>\n",
       "      <td>Sainte Jacques-les-Bains</td>\n",
       "      <td>2023-02-14</td>\n",
       "      <td>2025-10-23</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   client_id      nom      prenom                             email  \\\n",
       "0          1      Rey  Alexandrie           alexandrie.rey@live.com   \n",
       "1          2  Lagarde      Eug√®ne           eug√®ne.lagarde@yahoo.fr   \n",
       "2          3   Gaudin       Aim√©e               aim√©e.gaudin@sfr.fr   \n",
       "3          4   Faivre        No√´l              no√´l.faivre@voila.fr   \n",
       "4          5    Faure   V√©ronique  v√©ronique.faure@club-internet.fr   \n",
       "\n",
       "                      ville date_inscription derniere_activite  \n",
       "0                   Lejeune       2023-10-15        2025-01-21  \n",
       "1                       NaN       2024-07-31        2025-08-25  \n",
       "2                  Lopezdan       2024-01-03        2025-10-19  \n",
       "3              Saint Eug√®ne       2023-08-01        2025-07-11  \n",
       "4  Sainte Jacques-les-Bains       2023-02-14        2025-10-23  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 520 entries, 0 to 519\n",
      "Data columns (total 7 columns):\n",
      " #   Column             Non-Null Count  Dtype \n",
      "---  ------             --------------  ----- \n",
      " 0   client_id          520 non-null    int64 \n",
      " 1   nom                520 non-null    object\n",
      " 2   prenom             520 non-null    object\n",
      " 3   email              520 non-null    object\n",
      " 4   ville              428 non-null    object\n",
      " 5   date_inscription   520 non-null    object\n",
      " 6   derniere_activite  520 non-null    object\n",
      "dtypes: int64(1), object(6)\n",
      "memory usage: 28.6+ KB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "None"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "---Taux de valeurs manquantes (%)---\n",
      "ville    17.692308\n",
      "dtype: float64\n",
      "\n",
      "--- V√©rification des doublons ---\n",
      "Nombre total de doublons: 18 / soit 3.46%\n",
      "\n",
      "--- V√©rification des doublons sur le client_id ---\n",
      "Nombre de client_id en doublon : 20\n",
      "\n",
      "--- V√©rification de compl√©tude : nom et pr√©nom ---\n",
      "Nombre de noms manquants : 0\n",
      "Nombre de pr√©noms manquants : 0\n",
      "\n",
      "--- V√©rification de coh√©rence des dates --- \n",
      "Incoh√©rences d√©tect√©es : 0 (0.00%)\n"
     ]
    }
   ],
   "source": [
    "print(\"AUDIT DATAFRAME CLIENTS\")\n",
    "\n",
    "display(df_clients.head())\n",
    "display(df_clients.info())\n",
    "\n",
    "print(\"\\n---Taux de valeurs manquantes (%)---\")\n",
    "missing_percentage = df_clients.isnull().sum() / len(df_clients) * 100\n",
    "print(missing_percentage[missing_percentage > 0].sort_values(ascending=False))\n",
    "\n",
    "print(\"\\n--- V√©rification des doublons ---\")\n",
    "clients_doublons = df_clients.duplicated().sum()\n",
    "print(f\"Nombre total de doublons: {clients_doublons} / soit {clients_doublons/len(df_clients) * 100:.2f}%\")\n",
    "\n",
    "print(\"\\n--- V√©rification des doublons sur le client_id ---\")\n",
    "nb_doublons_id = df_clients['client_id'].duplicated().sum()\n",
    "print(f\"Nombre de client_id en doublon : {nb_doublons_id}\")\n",
    "\n",
    "print(\"\\n--- V√©rification de compl√©tude : nom et pr√©nom ---\")\n",
    "nb_nom_manquant = df_clients['nom'].isna().sum()\n",
    "nb_prenom_manquant = df_clients['prenom'].isna().sum()\n",
    "print(f\"Nombre de noms manquants : {nb_nom_manquant}\")\n",
    "print(f\"Nombre de pr√©noms manquants : {nb_prenom_manquant}\")\n",
    "\n",
    "print(\"\\n--- V√©rification de coh√©rence des dates --- \")\n",
    "df_clients['date_inscription'] = pd.to_datetime(df_clients['date_inscription'], errors='coerce')\n",
    "df_clients['derniere_activite'] = pd.to_datetime(df_clients['derniere_activite'], errors='coerce')\n",
    "\n",
    "mask_incoherence = df_clients['date_inscription'] > df_clients['derniere_activite']\n",
    "\n",
    "nb_incoherences = mask_incoherence.sum()\n",
    "pct_incoherences = (nb_incoherences / len(df_clients)) * 100\n",
    "\n",
    "print(f\"Incoh√©rences d√©tect√©es : {nb_incoherences} ({pct_incoherences:.2f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ae6480b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- AUDIT DES EMAILS ---\n",
      "Emails valides : 343 (66.0%)\n",
      "Emails = 'invalid_email' : 10 (1.9%)\n",
      "Emails invalides (pr√©sence d'accents) : 167 (32.1%)\n",
      "Emails null : 0 (0.0%)\n",
      "\n",
      " Exemples d'emails invalides (hors 'invalid_email') :\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>email</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>eug√®ne.lagarde@yahoo.fr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>aim√©e.gaudin@sfr.fr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>no√´l.faivre@voila.fr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>v√©ronique.faure@club-internet.fr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>c√©line.benard@sfr.fr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>fr√©d√©rique.fabre@orange.fr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>charles.dupr√©@voila.fr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>√©mile.lecoq@hotmail.fr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>th√©ophile.potier@bouygtel.fr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>p√©n√©lope.delahaye@noos.fr</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               email\n",
       "1            eug√®ne.lagarde@yahoo.fr\n",
       "2                aim√©e.gaudin@sfr.fr\n",
       "3               no√´l.faivre@voila.fr\n",
       "4   v√©ronique.faure@club-internet.fr\n",
       "10              c√©line.benard@sfr.fr\n",
       "12        fr√©d√©rique.fabre@orange.fr\n",
       "16            charles.dupr√©@voila.fr\n",
       "27            √©mile.lecoq@hotmail.fr\n",
       "32      th√©ophile.potier@bouygtel.fr\n",
       "37         p√©n√©lope.delahaye@noos.fr"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(\"\\n--- AUDIT DES EMAILS ---\")\n",
    "\n",
    "email_pattern = r'^[a-zA-Z0-9._%+-]+@[a-zA-Z0-9.-]+\\.[a-zA-Z]{2,}$'\n",
    "\n",
    "# Compter sp√©cifiquement \"invalid_email\"\n",
    "nb_invalid_email = (df_clients['email'] == 'invalid_email').sum()\n",
    "\n",
    "# Validation des autres emails\n",
    "mask_valide = df_clients['email'].apply(\n",
    "    lambda x: bool(re.match(email_pattern, str(x).strip())) if pd.notna(x) else False\n",
    ")\n",
    "\n",
    "nb_valides = mask_valide.sum()\n",
    "nb_invalides_autres = (~mask_valide & df_clients['email'].notna() & (df_clients['email'] != 'invalid_email')).sum()\n",
    "nb_nulls = df_clients['email'].isna().sum()\n",
    "\n",
    "print(f\"Emails valides : {nb_valides} ({(nb_valides/len(df_clients)*100):.1f}%)\")\n",
    "print(f\"Emails = 'invalid_email' : {nb_invalid_email} ({(nb_invalid_email/len(df_clients)*100):.1f}%)\")\n",
    "print(f\"Emails invalides (pr√©sence d'accents) : {nb_invalides_autres} ({(nb_invalides_autres/len(df_clients)*100):.1f}%)\")\n",
    "print(f\"Emails null : {nb_nulls} ({(nb_nulls/len(df_clients)*100):.1f}%)\")\n",
    "\n",
    "# Afficher des exemples d'emails invalides (hors \"invalid_email\")\n",
    "if nb_invalides_autres > 0:\n",
    "    print(\"\\n Exemples d'emails invalides (hors 'invalid_email') :\")\n",
    "    emails_invalides_autres = df_clients[\n",
    "        ~mask_valide &\n",
    "        df_clients['email'].notna() &\n",
    "        (df_clients['email'] != 'invalid_email')\n",
    "    ]\n",
    "    display(emails_invalides_autres[['email']].head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5f4c32f",
   "metadata": {},
   "source": [
    "## On v√©rifie si les villes renseign√©es existent\n",
    "## Le script est long (~1min30 pour tester chaque ville)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3ce038ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- VALIDATION DES NOMS DE VILLES ---\n",
      "Villes valides : 87 soit 24%\n",
      "Villes invalides : 272 soit 76%\n",
      "\n",
      "Nombre de lignes affect√©es : 317 soit 61%\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ville</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Lejeune</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Lopezdan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Sainte Jacques-les-Bains</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Petit-sur-Mer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Sainte Lucieboeuf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Augernec</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Pichon-sur-Mer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Blanc-sur-Mer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Saint ValentineVille</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Saint Thomasdan</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       ville\n",
       "0                    Lejeune\n",
       "2                   Lopezdan\n",
       "4   Sainte Jacques-les-Bains\n",
       "6              Petit-sur-Mer\n",
       "14         Sainte Lucieboeuf\n",
       "15                  Augernec\n",
       "16            Pichon-sur-Mer\n",
       "17             Blanc-sur-Mer\n",
       "19      Saint ValentineVille\n",
       "22           Saint Thomasdan"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(\"\\n--- VALIDATION DES NOMS DE VILLES ---\")\n",
    "\n",
    "def valider_villes_dataframe(df, colonne_ville='ville'):\n",
    "    villes_uniques = df[colonne_ville].dropna().unique()\n",
    "\n",
    "    villes_invalides = []\n",
    "    villes_valides = []\n",
    "\n",
    "    for ville in villes_uniques:\n",
    "        url = f\"https://geo.api.gouv.fr/communes?nom={ville}&limit=1\"\n",
    "        try:\n",
    "            response = requests.get(url, timeout=5)\n",
    "            if response.status_code == 200 and len(response.json()) > 0:\n",
    "                villes_valides.append(ville)\n",
    "            else:\n",
    "                villes_invalides.append(ville)\n",
    "        except:\n",
    "            villes_invalides.append(ville)\n",
    "\n",
    "    print(f\"Villes valides : {len(villes_valides)} soit {len(villes_valides)/len(villes_uniques)*100:.0f}%\")\n",
    "    print(f\"Villes invalides : {len(villes_invalides)} soit {len(villes_invalides)/len(villes_uniques)*100:.0f}%\")\n",
    "\n",
    "    if villes_invalides:\n",
    "        # Afficher les lignes concern√©es\n",
    "        mask_invalides = df[colonne_ville].isin(villes_invalides)\n",
    "        print(f\"\\nNombre de lignes affect√©es : {mask_invalides.sum()} soit {mask_invalides.sum()/len(df_clients)*100:.0f}%\")\n",
    "        display(df[mask_invalides][[colonne_ville]].head(10))\n",
    "\n",
    "    return villes_valides, villes_invalides\n",
    "\n",
    "villes_valides, villes_invalides = valider_villes_dataframe(df_clients)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d7751889",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ventes = pd.read_csv('../data/raw/Ventes_Q1_2025.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "eaa3dbcf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- POLITIQUE DE CONSERVATION RGPD ---\n",
      "Date de r√©f√©rence : 2025-10-29\n",
      "Politique : 3 ans actif + 5 ans archive\n",
      "\n",
      "--- R√©partition des actions RGPD ---\n",
      "‚úÖ CONSERVER                     :   520 (100.0%)\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n--- POLITIQUE DE CONSERVATION RGPD ---\")\n",
    "\n",
    "# Configuration\n",
    "DUREE_CONSERVATION_STANDARD = 3  # ann√©es\n",
    "DUREE_CONSERVATION_PROSPECT = 3  # ann√©es (prospects non-acheteurs)\n",
    "DUREE_ARCHIVAGE = 5  # ann√©es suppl√©mentaires en archive\n",
    "\n",
    "# Convertir dates en for√ßant les erreurs √† NaT\n",
    "df_clients['derniere_activite'] = pd.to_datetime(df_clients['derniere_activite'], errors='coerce')\n",
    "df_clients['date_inscription'] = pd.to_datetime(df_clients['date_inscription'], errors='coerce')\n",
    "date_reference = pd.to_datetime(df_ventes['date']).max()\n",
    "\n",
    "# V√©rifier s'il y a des dates invalides\n",
    "nb_dates_invalides = df_clients['derniere_activite'].isna().sum()\n",
    "if nb_dates_invalides > 0:\n",
    "    print(f\"‚ö†Ô∏è {nb_dates_invalides} dates invalides d√©tect√©es dans 'derniere_activite'\")\n",
    "\n",
    "# Identifier si le client a d√©j√† achet√©\n",
    "clients_acheteurs = df_ventes['client_id'].unique()\n",
    "df_clients['a_achete'] = df_clients['client_id'].isin(clients_acheteurs)\n",
    "\n",
    "# Calculer l'anciennet√© (en g√©rant les NaT)\n",
    "df_clients['annees_inactivite'] = (date_reference - df_clients['derniere_activite']).dt.days / 365\n",
    "\n",
    "# D√©terminer l'action RGPD\n",
    "def determiner_action_rgpd(row):\n",
    "    # Si pas de date d'activit√© valide, consid√©rer comme √† supprimer\n",
    "    if pd.isna(row['annees_inactivite']):\n",
    "        return \"SUPPRIMER (date invalide)\"\n",
    "\n",
    "    if row['a_achete']:\n",
    "        if row['annees_inactivite'] > DUREE_CONSERVATION_STANDARD + DUREE_ARCHIVAGE:\n",
    "            return \"SUPPRIMER\"\n",
    "        elif row['annees_inactivite'] > DUREE_CONSERVATION_STANDARD:\n",
    "            return \"ARCHIVER\"\n",
    "        else:\n",
    "            return \"CONSERVER\"\n",
    "    else:  # Prospect\n",
    "        if row['annees_inactivite'] > DUREE_CONSERVATION_PROSPECT:\n",
    "            return \"SUPPRIMER\"\n",
    "        else:\n",
    "            return \"CONSERVER\"\n",
    "\n",
    "df_clients['action_rgpd'] = df_clients.apply(determiner_action_rgpd, axis=1)\n",
    "\n",
    "# Statistiques\n",
    "stats_actions = df_clients['action_rgpd'].value_counts()\n",
    "total = len(df_clients)\n",
    "\n",
    "print(f\"Date de r√©f√©rence : {date_reference.date()}\")\n",
    "print(f\"Politique : {DUREE_CONSERVATION_STANDARD} ans actif + {DUREE_ARCHIVAGE} ans archive\\n\")\n",
    "\n",
    "print(\"--- R√©partition des actions RGPD ---\")\n",
    "for action in [\"CONSERVER\", \"ARCHIVER\", \"SUPPRIMER\", \"SUPPRIMER (date invalide)\"]:\n",
    "    count = stats_actions.get(action, 0)\n",
    "    if count > 0:\n",
    "        pourcentage = (count / total * 100)\n",
    "        emoji = \"‚úÖ\" if action == \"CONSERVER\" else \"üì¶\" if action == \"ARCHIVER\" else \"üóëÔ∏è\"\n",
    "        print(f\"{emoji} {action:30s}: {count:5d} ({pourcentage:5.1f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c74e8a71",
   "metadata": {},
   "source": [
    "# Correction du dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7596d890",
   "metadata": {},
   "source": [
    "## Suppression des doublons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "051ce32d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- SUPPRESSION DES DOUBLONS ---\n",
      "Lignes avant : 520\n",
      "Lignes apr√®s : 502\n",
      "Nombre de doublons restants: 0\n",
      "\n",
      "--- V√©rification des doublons sur le client_id ---\n",
      "Nombre de client_id en doublon : 0\n",
      "\n",
      "--- V√©rification des doublons sur l'email autres que  invalid_email---\n",
      "Nombre d'emails en doublon (hors 'invalid_email') : 0\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n--- SUPPRESSION DES DOUBLONS ---\")\n",
    "\n",
    "df_clients_without_duplicate = df_clients.drop_duplicates()\n",
    "print(f\"Lignes avant : {len(df_clients)}\")\n",
    "print(f\"Lignes apr√®s : {len(df_clients_without_duplicate)}\")\n",
    "print(f\"Nombre de doublons restants: {df_clients_without_duplicate.duplicated().sum()}\")\n",
    "\n",
    "# suppression sp√©ciale pour les doublons sur l'id (obligation d'unicit√©)\n",
    "df_clients_without_duplicate = df_clients_without_duplicate.drop_duplicates(subset=['client_id'], keep='first')\n",
    "\n",
    "print(\"\\n--- V√©rification des doublons sur le client_id ---\")\n",
    "nb_doublons_id = df_clients_without_duplicate['client_id'].duplicated().sum()\n",
    "print(f\"Nombre de client_id en doublon : {nb_doublons_id}\")\n",
    "\n",
    "\n",
    "if nb_doublons_id > 0:\n",
    "    # Afficher les client_id en doublon\n",
    "    client_id_dupliques = df_clients_without_duplicate[df_clients_without_duplicate['client_id'].duplicated(keep=False)]\n",
    "    print(f\"\\nNombre total de lignes concern√©es : {len(client_id_dupliques)}\")\n",
    "\n",
    "    # Afficher quelques exemples de doublons\n",
    "    print(\"\\nExemples de lignes avec client_id en doublon :\")\n",
    "    display(client_id_dupliques.sort_values('client_id').head(10))\n",
    "\n",
    "print(\"\\n--- V√©rification des doublons sur l'email autres que  invalid_email---\")\n",
    "df_emails_valides = df_clients_without_duplicate[df_clients_without_duplicate['email'] != 'invalid_email']\n",
    "nb_doublons_email = df_emails_valides['email'].duplicated().sum()\n",
    "\n",
    "print(f\"Nombre d'emails en doublon (hors 'invalid_email') : {nb_doublons_email}\")\n",
    "\n",
    "if nb_doublons_email > 0:\n",
    "    # Afficher les client_email en doublon\n",
    "    client_email_dupliques = df_clients_without_duplicate[df_clients_without_duplicate['email'].duplicated(keep=False)]\n",
    "    print(f\"\\nNombre total de lignes concern√©es : {len(client_email_dupliques)}\")\n",
    "\n",
    "    # Afficher quelques exemples de doublons\n",
    "    print(\"\\nExemples de lignes avec email en doublon :\")\n",
    "    display(client_email_dupliques.sort_values('email').head(10))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a810a281",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- SAUVEGARDE DU FICHIER NETTOYE ---\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n--- SAUVEGARDE DU FICHIER NETTOYE ---\")\n",
    "\n",
    "# Sauvegarder dans le dossier processed\n",
    "df_clients_without_duplicate.to_csv('../data/processed/Clients_Master_corrected.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdfe8b5d",
   "metadata": {},
   "source": [
    "# Correction des noms de ville par Fuzzy Matching \n",
    "### Penser √† installer la librairie : pip install fuzzywuzzy python-Levenshtein\n",
    "### ‚ö†Ô∏è Script long: >7min"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "58bc0061",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ 33610 communes charg√©es\n",
      "\n",
      "--- VALIDATION ET CORRECTION DES VILLES ---\n",
      "\n",
      "--- APPLICATION DES CORRECTIONS ---\n",
      "‚úÖ 1353 lignes corrig√©es\n",
      "‚ö†Ô∏è 13 lignes avec un nom de ville inexploitable -> remplac√© par null\n",
      "\n",
      "üìã √âtat final apr√®s correction\n",
      "Villes valides : 399\n",
      "Villes null : 101\n"
     ]
    }
   ],
   "source": [
    "# Chargement du DataFrame pr√©c√©demment nettoy√©\n",
    "df_clients_cleaned = pd.read_csv('../data/processed/Clients_Master_corrected.csv')\n",
    "\n",
    "# Charger le r√©f√©rentiel des communes\n",
    "url_communes = \"https://www.data.gouv.fr/fr/datasets/r/dbe8a621-a9c4-4bc3-9cae-be1699c5ff25\"\n",
    "communes_france = pd.read_csv(url_communes, sep=',')\n",
    "\n",
    "# Cr√©er une liste des noms de communes (en conservant la casse originale)\n",
    "noms_communes_lower = set(communes_france['nom_commune_complet'].str.lower())\n",
    "noms_communes_original = communes_france['nom_commune_complet'].tolist()\n",
    "\n",
    "print(f\"‚úÖ {len(noms_communes_lower)} communes charg√©es\")\n",
    "\n",
    "def corriger_ville_automatique(nom_ville, villes_reference):\n",
    "    \"\"\"Trouve la ville la plus proche dans le r√©f√©rentiel\"\"\"\n",
    "    if pd.isna(nom_ville):\n",
    "        return None\n",
    "\n",
    "    meilleur_match, score = process.extractOne(nom_ville, villes_reference)\n",
    "\n",
    "    if score > 80:  # Seuil de similarit√©\n",
    "        return meilleur_match\n",
    "    return None\n",
    "\n",
    "print(\"\\n--- VALIDATION ET CORRECTION DES VILLES ---\")\n",
    "\n",
    "# Identifier les villes invalides\n",
    "villes_uniques = df_clients_cleaned['ville'].dropna().unique()\n",
    "villes_a_corriger = {}\n",
    "\n",
    "for ville in villes_uniques:\n",
    "    if ville.lower() not in noms_communes_lower:\n",
    "        # Ville invalide, chercher une correction\n",
    "        ville_corrigee = corriger_ville_automatique(ville, noms_communes_original)\n",
    "        if ville_corrigee:\n",
    "            villes_a_corriger[ville] = ville_corrigee\n",
    "        else:\n",
    "            villes_a_corriger[ville] = None\n",
    "\n",
    "\n",
    "# Appliquer les corrections\n",
    "if villes_a_corriger:\n",
    "    print(f\"\\n--- APPLICATION DES CORRECTIONS ---\")\n",
    "\n",
    "    nb_corrections = 0\n",
    "    nb_null = 0\n",
    "\n",
    "    for ville_invalide, ville_corrigee in villes_a_corriger.items():\n",
    "        if ville_corrigee:\n",
    "            # Correction automatique r√©ussie\n",
    "            df_clients_cleaned['ville'] = df_clients_cleaned['ville'].replace(ville_invalide, ville_corrigee)\n",
    "            nb_corrections += (df_clients_cleaned['ville'] == ville_corrigee).sum()\n",
    "        else:\n",
    "            # Aucune correction trouv√©e ‚Üí remplacer par null\n",
    "            mask_invalide = df_clients_cleaned['ville'] == ville_invalide\n",
    "            nb_null += mask_invalide.sum()\n",
    "            df_clients_cleaned.loc[mask_invalide, 'ville'] = None\n",
    "\n",
    "    print(f\"‚úÖ {nb_corrections} lignes corrig√©es\")\n",
    "    print(f\"‚ö†Ô∏è {nb_null} lignes avec un nom de ville inexploitable -> remplac√© par null\")\n",
    "else:\n",
    "    print(\"\\n‚úÖ Toutes les villes sont valides, aucune correction n√©cessaire\")\n",
    "\n",
    "# Afficher le r√©sultat\n",
    "print(f\"\\nüìã √âtat final apr√®s correction\")\n",
    "print(f\"Villes valides : {df_clients_cleaned['ville'].notna().sum()}\")\n",
    "print(f\"Villes null : {df_clients_cleaned['ville'].isna().sum()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1785d0a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Villes valides : 179 soit 98%\n",
      "Villes invalides : 4 soit 2%\n",
      "\n",
      "Nombre de lignes affect√©es : 4 soit 1%\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ville</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>105</th>\n",
       "      <td>Le Mesnil-Mauger</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129</th>\n",
       "      <td>√âvaill√©</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>275</th>\n",
       "      <td>Saint-Gabriel-Br√©cy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>443</th>\n",
       "      <td>St barthelemy</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   ville\n",
       "105     Le Mesnil-Mauger\n",
       "129              √âvaill√©\n",
       "275  Saint-Gabriel-Br√©cy\n",
       "443        St barthelemy"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Validation de la correction apport√©e\n",
    "villes_valides, villes_invalides = valider_villes_dataframe(df_clients_cleaned)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ead2ab2a",
   "metadata": {},
   "source": [
    "### Ce sont des faux-n√©gatifs, ces quatres villes existent bien.\n",
    "<br>Il doit y avoir un probl√®me de r√©f√©rencement entre les deux sources utilis√©es pour la correction\n",
    "<br> On peut consid√©rer que la correction a r√©ussi √† traiter tout ce qui √©tait possible"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "430d9121",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- SAUVEGARDE DU FICHIER AVEC VILLES CORRIGEES ---\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n--- SAUVEGARDE DU FICHIER AVEC VILLES CORRIGEES ---\")\n",
    "\n",
    "# Sauvegarder dans le dossier processed\n",
    "df_clients_cleaned.to_csv('../data/processed/Clients_Master_corrected.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "76bd4960",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- NETTOYAGE DES EMAILS (accents + casse) ---\n",
      "\n",
      "--- AUDIT DES EMAILS ---\n",
      "Emails valides : 490 (98.0%)\n",
      "Emails = 'invalid_email' : 10 (2.0%)\n",
      "Emails invalides (pr√©sence d'accents ou espaces) : 0 (0.0%)\n",
      "Emails null : 0 (0.0%)\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n--- NETTOYAGE DES EMAILS (accents + casse) ---\")\n",
    "df_clients_cleaned = pd.read_csv('../data/processed/Clients_Master_corrected.csv')\n",
    "\n",
    "def nettoyer_email(email):\n",
    "    \"\"\"Retire les accents et met en minuscules\"\"\"\n",
    "    if pd.isna(email):\n",
    "        return email\n",
    "\n",
    "    email_str = str(email).strip().lower()  # Minuscules et trim\n",
    "\n",
    "    # Supprimer tous les espaces\n",
    "    email_str = email_str.replace(' ', '')\n",
    "\n",
    "    # Retirer les accents\n",
    "    email_normalise = unicodedata.normalize('NFD', email_str)\n",
    "    email_propre = ''.join(\n",
    "        char for char in email_normalise\n",
    "        if unicodedata.category(char) != 'Mn'\n",
    "    )\n",
    "\n",
    "    return email_propre\n",
    "\n",
    "# Appliquer le nettoyage\n",
    "df_clients_cleaned['email'] = df_clients_cleaned['email'].apply(nettoyer_email)\n",
    "\n",
    "print(\"\\n--- AUDIT DES EMAILS ---\")\n",
    "\n",
    "email_pattern = r'^[a-zA-Z0-9._%+-]+@[a-zA-Z0-9.-]+\\.[a-zA-Z]{2,}$'\n",
    "\n",
    "# Compter sp√©cifiquement \"invalid_email\"\n",
    "nb_invalid_email = (df_clients_cleaned['email'] == 'invalid_email').sum()\n",
    "\n",
    "# Validation des autres emails\n",
    "mask_valide = df_clients_cleaned['email'].apply(\n",
    "    lambda x: bool(re.match(email_pattern, str(x).strip())) if pd.notna(x) else False\n",
    ")\n",
    "\n",
    "nb_valides = mask_valide.sum()\n",
    "nb_invalides_autres = (~mask_valide & df_clients_cleaned['email'].notna() & (df_clients_cleaned['email'] != 'invalid_email')).sum()\n",
    "nb_nulls = df_clients_cleaned['email'].isna().sum()\n",
    "\n",
    "print(f\"Emails valides : {nb_valides} ({(nb_valides/len(df_clients_cleaned)*100):.1f}%)\")\n",
    "print(f\"Emails = 'invalid_email' : {nb_invalid_email} ({(nb_invalid_email/len(df_clients_cleaned)*100):.1f}%)\")\n",
    "print(f\"Emails invalides (pr√©sence d'accents ou espaces) : {nb_invalides_autres} ({(nb_invalides_autres/len(df_clients_cleaned)*100):.1f}%)\")\n",
    "print(f\"Emails null : {nb_nulls} ({(nb_nulls/len(df_clients_cleaned)*100):.1f}%)\")\n",
    "\n",
    "# Afficher des exemples d'emails invalides (hors \"invalid_email\")\n",
    "if nb_invalides_autres > 0:\n",
    "    print(\"\\n Exemples d'emails invalides (hors 'invalid_email') :\")\n",
    "    emails_invalides_autres = df_clients_cleaned[\n",
    "        ~mask_valide &\n",
    "        df_clients_cleaned['email'].notna() &\n",
    "        (df_clients_cleaned['email'] != 'invalid_email')\n",
    "    ]\n",
    "    display(emails_invalides_autres[['email']].head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "81f26faa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- SAUVEGARDE DU FICHIER AVEC EMAILS CORRIGEES ---\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n--- SAUVEGARDE DU FICHIER AVEC EMAILS CORRIGEES ---\")\n",
    "\n",
    "# Sauvegarder dans le dossier processed\n",
    "df_clients_cleaned.to_csv('../data/processed/Clients_Master_corrected.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "634aeaa5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TP_Data_M (3.12.3)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
